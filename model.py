# -*- coding: utf-8 -*-
"""House_Price_Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HA2pG34CkrvWXnZ284YwfTzIaD_ZRFie

# **House Price Prediction Model By Mirza Yasir Abdullah Baig**


## **Step No 1: Importing the Libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
import os
import pickle
import warnings
warnings.filterwarnings('ignore')
print('All Model Loaded Successfully...')

"""## **Step No 2: Loading the Dataset**"""

data = fetch_california_housing()

data.keys()

df = pd.DataFrame(data.data, columns = data.feature_names)
df['MedHouseVal'] = data.target

data.target_names

df.sample(5)

print(data['DESCR'])

"""## **Step No 3: Exploratory Data Analysis**"""

rows, cols = df.shape
print("No.of rows", rows)
print("No.of Columns", cols)

df.sample(5)

df.head()

df.tail()

df.describe()

df.isna().sum()

#There is no missing values in the data

df.columns

len(df.columns)

plt.figure(figsize=(12, 12))


for i in range(len(df.columns)):
  plt.subplot(3,3,i+1)
  plt.hist(df[df.columns[i]])
  plt.title(f'Distribution Analysis for {df.columns[i]}')
plt.show()

plt.figure(figsize=(10,10))
plt.title('correlation between Features')
sns.heatmap(df.corr(), annot = True, cmap = 'mako')

"""## **Step No 4: Data Preprocessing**

1.   List item
2.   List item


"""

X = df.iloc[:, :-2]

X

y = df['MedHouseVal']

y

#Min Max Scaler

scaler = MinMaxScaler()

scaled_X = scaler.fit_transform(X)

scaled_X

scaled_df = pd.DataFrame(scaled_X, columns = X.columns)

scaled_df

scaled_df.describe()

"""## **Step No 5: Train Test Part Data Divide**"""

X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.1, random_state = 32)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""## **Step No 6: Model Building ML**"""

model =  LinearRegression()

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

compare_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

compare_df

"""## **Step No 7: Model Evaluation**"""

score = model.score(X_test, y_test)
print('Model Score:', score)

mae = mean_absolute_error(y_test, y_pred)
print('Mean Absolute Error:', mae)

mse = mean_squared_error(y_test, y_pred)
print('Mean squared Error:', mse)

rmse = root_mean_squared_error(y_test, y_pred)
print('Root Mean Squared Error:', rmse)

"""## **Step No 8: Final Model Checking**"""

matrix_dict = {'Model Number': [], 'Model':[], 'Model Score':[], 'Mean Absolute Error':[], 'Mean Squared Error':[], 'Root Mean Squared Error':[]}

for i in range(5000):
  X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.1, random_state = i)
  model = LinearRegression()
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  score = model.score(X_test, y_test)
  mae = mean_absolute_error(y_test, y_pred)
  mse = mean_squared_error(y_test, y_pred)
  rmse = root_mean_squared_error(y_test, y_pred)

  matrix_dict['Model Number'].append(i)
  matrix_dict['Model'].append(model)
  matrix_dict['Model Score'].append(score)
  matrix_dict['Mean Absolute Error'].append(mae)
  matrix_dict['Mean Squared Error'].append(mse)
  matrix_dict['Root Mean Squared Error'].append(rmse)
  print(f'{i} Model Done')
  display(clear = True)
matrix_df = pd.DataFrame(matrix_dict)
print("All Done")

matrix_df

matrix_df['Model Score'].max()

matrix_df['Model Score'].min()

final_model_df = matrix_df[matrix_df['Model Score'] == matrix_df['Model Score'].max()]

matrix_positive_df = matrix_df[matrix_df['Model Score'] >= 0.50]

plt.plot(matrix_positive_df['Model Number'], matrix_positive_df['Model Score']* 100)
plt.xlabel('Model Number')
plt.ylabel('Model Score')
plt.title('Model Number vs Model Score')
plt.show()

"""## **Step No 9: Saving The Final Model**


"""

final_model = final_model_df['Model']

# Get the actual LinearRegression model from the DataFrame
final_model = final_model_df['Model'].values[0]  # pick the first/best model

# Save the actual model
with open('AIModel_For_House.pkl', 'wb') as f:
    pickle.dump(final_model, f)

print("Model Saved Successfully")

# Save the fitted scaler to use in Streamlit app
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

"""## **Step No 10: Load the model**"""

with open("AIModel_For_House.pkl", "rb") as f:
    model = pickle.load(f)

print(type(model))  # Should show <class 'sklearn.linear_model._base.LinearRegression'>
